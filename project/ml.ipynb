{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOSPzFl4cV8KzifATIYPakG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#regression model\n","\n","#import\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","#dataset\n","df=pd.read_csv('data.csv')\n","X=df.iloc[:,:-1].values\n","y=df.iloc[:,-1].values\n","\n","#filling na values\n","from sklearn.impute import SimpleImputer\n","imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n","imputer.fit(X[:,1:3])\n","X[:,1:3]=imputer.transform(X[:,1:3])\n","\n","#label encoder on 1st column\n","from sklearn.preprocessing import LabelEncoder\n","le=LabelEncoder()\n","X[:,0]=le.fit_transform(X[:,0])\n","\n","#one hot encoder on 2nd column\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct= ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder='passthrough')\n","X=np.array(ct.fit_transform(X))\n","\n","#train test split\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)\n","\n","#feature sacling\n","from sklearn.preprocessing import StandardScaler\n","sc=StandardScaler()\n","X_train[:,3:]=sc.fit_transform(X_train[:,3:])\n","X_test[:,3:]=sc.transform(X_test[:,3:])\n","\n","#dimension reducion - pca\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components = 2)\n","X_train = pca.fit_transform(X_train)\n","X_test = pca.transform(X_test)\n","\n","#dimension reducion - lda\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","lda = LDA(n_components = 2)\n","X_train = lda.fit_transform(X_train, y_train)\n","X_test = lda.transform(X_test)\n","\n","#dimension reducion - kernel pca\n","from sklearn.decomposition import KernelPCA\n","kpca = KernelPCA(n_components = 2, kernel = 'rbf')\n","X_train = kpca.fit_transform(X_train)\n","X_test = kpca.transform(X_test)\n","\n","#model train\n","from sklearn.linear_model import LinearRegression\n","regressor=LinearRegression()\n","regressor.fit(X_train,y_train)\n","\n","#model predict\n","y_pred=regressor.predict(X_test)\n","\n","#plt training\n","plt.scatter(X_train,y_train,color='red')\n","plt.plot(X_train,regressor.predict(X_train),color='blue')\n","plt.title('Salary vs Experience (Training set)')\n","plt.xlabel('Years of Experience')\n","plt.ylabel('Salary')\n","plt.show()\n","\n","#plt test\n","plt.scatter(X_test,y_test,color='red')\n","plt.plot(X_train,regressor.predict(X_train),color='blue')\n","plt.title('Salary vs Experience (Test set)')\n","plt.xlabel('Years of Experience')\n","plt.ylabel('Salary')\n","plt.show()"],"metadata":{"id":"iUOP4OIR8ygj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#deep learning ann\n","\n","#import\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","#dataset\n","dataset = pd.read_csv('/Churn_Modelling.csv')\n","X = dataset.iloc[:, 3:-1].values\n","y = dataset.iloc[:, -1].values\n","\n","#label encoder for 3rd column\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","X[:, 2] = le.fit_transform(X[:, 2])\n","\n","#one hot encoding for 2nd column\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n","X = np.array(ct.fit_transform(X))\n","\n","#train test split\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n","\n","#feature scaling\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","#ann init\n","ann = tf.keras.models.Sequential()\n","\n","#1st hidden layer\n","ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n","\n","#2nd hidden layer\n","ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n","\n","#output layer\n","ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n","\n","#compiling ann\n","ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","\n","#training ann\n","ann.fit(X_train, y_train, batch_size = 32, epochs = 10)\n","\n","#predict one sample\n","print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)\n","\n","#predict test dataset\n","y_pred = ann.predict(X_test)\n","y_pred = (y_pred > 0.5)\n","print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n","\n","#confusion matrix\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)"],"metadata":{"id":"ksUEywW0wdBb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#cnn\n","\n","#import\n","import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","#preprocessing training set\n","train_datagen = ImageDataGenerator(rescale = 1./255,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n","training_set = train_datagen.flow_from_directory('dataset/training_set',target_size = (64, 64), batch_size = 32, class_mode = 'binary')\n","\n","#preprocessing test set\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","test_set = test_datagen.flow_from_directory('dataset/test_set', target_size = (64, 64), batch_size = 32, class_mode = 'binary')\n","\n","#cnn init\n","cnn = tf.keras.models.Sequential()\n","\n","#convolution\n","cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n","\n","#pooling\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n","\n","#convolution layer 2nd\n","cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n","\n","#flattening\n","cnn.add(tf.keras.layers.Flatten())\n","\n","#full connection\n","cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n","\n","#output layer\n","cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n","\n","#cnn compiling\n","cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","\n","#cnn training/validating\n","cnn.fit(x = training_set, validation_data = test_set, epochs = 25)\n","\n","#single predicton\n","import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = cnn.predict(test_image)\n","training_set.class_indices\n","if result[0][0] == 1:prediction = 'dog'\n","else:prediction = 'cat'"],"metadata":{"id":"MjYlD_4PB1ut"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#k fold cross validation\n","\n","#import\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","#dataset\n","dataset = pd.read_csv('Social_Network_Ads.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values\n","\n","#split\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n","\n","#feature scaling\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","#model\n","from sklearn.svm import SVC\n","classifier = SVC(kernel = 'rbf', random_state = 0)\n","classifier.fit(X_train, y_train)\n","\n","#confusion matrix\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","y_pred = classifier.predict(X_test)\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)\n","\n","#k fold cross validation\n","from sklearn.model_selection import cross_val_score\n","accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n","print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n","print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n","\n","#visualizing training result\n","from matplotlib.colors import ListedColormap\n","X_set, y_set = X_train, y_train\n","X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n","                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n","plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n","             alpha = 0.75, cmap = ListedColormap(('salmon', 'dodgerblue')))\n","plt.xlim(X1.min(), X1.max())\n","plt.ylim(X2.min(), X2.max())\n","for i, j in enumerate(np.unique(y_set)):\n","    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n","                c = ListedColormap(('salmon', 'dodgerblue'))(i), label = j)\n","plt.title('Kernel SVM (Training set)')\n","plt.xlabel('Age')\n","plt.ylabel('Estimated Salary')\n","plt.legend()\n","plt.show()\n","\n","#visualizing test result\n","from matplotlib.colors import ListedColormap\n","X_set, y_set = X_test, y_test\n","X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n","                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n","plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n","             alpha = 0.75, cmap = ListedColormap(('salmon', 'dodgerblue')))\n","plt.xlim(X1.min(), X1.max())\n","plt.ylim(X2.min(), X2.max())\n","for i, j in enumerate(np.unique(y_set)):\n","    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n","                c = ListedColormap(('salmon', 'dodgerblue'))(i), label = j)\n","plt.title('Kernel SVM (Test set)')\n","plt.xlabel('Age')\n","plt.ylabel('Estimated Salary')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"IJmflUJ0k-8s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#grid search\n","\n","#import\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","#dataset\n","dataset = pd.read_csv('Social_Network_Ads.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values\n","\n","#split\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n","\n","#feature scaling\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","#model\n","from sklearn.svm import SVC\n","classifier = SVC(kernel = 'rbf', random_state = 0)\n","classifier.fit(X_train, y_train)\n","\n","#confusion matrix\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","y_pred = classifier.predict(X_test)\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)\n","\n","#grid search\n","from sklearn.model_selection import GridSearchCV\n","parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n","              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n","grid_search = GridSearchCV(estimator = classifier,\n","                           param_grid = parameters,\n","                           scoring = 'accuracy',\n","                           cv = 10,\n","                           n_jobs = -1)\n","grid_search.fit(X_train, y_train)\n","best_accuracy = grid_search.best_score_\n","best_parameters = grid_search.best_params_\n","print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n","print(\"Best Parameters:\", best_parameters)"],"metadata":{"id":"PSHltYgLluvT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#xgboost\n","\n","#import\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","#dataset\n","dataset = pd.read_csv('Data.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values\n","\n","#split\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n","\n","#model\n","from xgboost import XGBClassifier\n","classifier = XGBClassifier()\n","classifier.fit(X_train, y_train)\n","\n","#confusion matrix\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","y_pred = classifier.predict(X_test)\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)\n","\n","#kfold\n","from sklearn.model_selection import cross_val_score\n","accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n","print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n","print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n","\n"],"metadata":{"id":"Z6ovlCc2siLw"},"execution_count":null,"outputs":[]}]}
